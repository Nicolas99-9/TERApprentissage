{"layers": [{"name": "Embedding", "output_dim": 35, "W_constraint": null, "input_shape": [20304], "cache_enabled": true, "init": "uniform", "input_dim": 20304, "mask_zero": false, "W_regularizer": null, "activity_regularizer": null, "input_length": 35}, {"name": "LSTM", "inner_activation": "hard_sigmoid", "go_backwards": false, "output_dim": 128, "stateful": false, "cache_enabled": true, "init": "glorot_uniform", "inner_init": "orthogonal", "input_dim": 35, "return_sequences": false, "activation": "tanh", "forget_bias_init": "one", "input_length": null}, {"cache_enabled": true, "name": "Dropout", "p": 0.5}, {"b_constraint": null, "name": "Dense", "activity_regularizer": null, "W_constraint": null, "cache_enabled": true, "init": "glorot_uniform", "activation": "linear", "input_dim": null, "b_regularizer": null, "W_regularizer": null, "output_dim": 1}, {"cache_enabled": true, "activation": "sigmoid", "name": "Activation"}], "optimizer": {"epsilon": 1e-06, "lr": 0.009999999776482582, "name": "Adagrad"}, "class_mode": "binary", "name": "Sequential", "loss": "binary_crossentropy"}